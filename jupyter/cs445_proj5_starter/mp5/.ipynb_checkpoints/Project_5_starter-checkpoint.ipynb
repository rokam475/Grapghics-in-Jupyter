{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVd5QDvoQJvB"
   },
   "source": [
    "Project #5: Video Stitching and Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gd7scc-8QJvE"
   },
   "source": [
    "## CS445: Computational Photography - Spring 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "II0kMh4yULg_"
   },
   "source": [
    "### Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "08y2JntvQJvH"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13344/1408506528.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YGABkLumWBt_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# modify to where you store your project data including utils\n",
    "datadir = \"/content/drive/My Drive/cs445_projects/proj5/\" \n",
    "\n",
    "utilfn = datadir + \"utils.py\"\n",
    "!cp \"$utilfn\" .\n",
    "imagesfn = datadir + \"images\"\n",
    "!cp -r \"$imagesfn\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtjcEvWArExF"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13344/273689691.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#import ffmpeg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "#!pip uninstall opencv-python -y\n",
    "# downgrade OpenCV a bit to use SIFT\n",
    "#!pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n",
    "#!pip install ffmpeg-python # for converting to video\n",
    "\n",
    "import ffmpeg\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from numpy.linalg import svd, inv\n",
    "import utils\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QagOldZDQJvG"
   },
   "source": [
    "### Part I: Stitch two key frames \n",
    "\n",
    "#### This involves:\n",
    "1. compute homography H between two frames; \n",
    "2. project each frame onto the same surface;\n",
    "3. blend the surfaces.\n",
    "\n",
    "Check that your homography is correct by plotting four points that form a square in frame 270 and their projections in each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BulGTlesQJvZ"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_13344/2180263387.py, line 83)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Ryan\\AppData\\Local\\Temp/ipykernel_13344/2180263387.py\"\u001b[1;36m, line \u001b[1;32m83\u001b[0m\n\u001b[1;33m    n_to_sample = ???? # Put the correct number of points here\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def score_projection(pt1, pt2):\n",
    "    '''\n",
    "    Score corresponding to the number of inliers for RANSAC\n",
    "    Input: pt1 and pt2 are 2xN arrays of N points such that pt1[:, i] and pt2[:,i] should be close in Euclidean distance if they are inliers\n",
    "    Outputs: score (scalar count of inliers) and inliers (1xN logical array)\n",
    "    '''\n",
    "\n",
    "    # TO DO\n",
    "    pointRange = len(pt1)\n",
    "    if pointRange != len(pt2):\n",
    "        print(\"mis match point length in score projection\")\n",
    "        \n",
    "    distance = []\n",
    "    for idx in range(pointRange):\n",
    "        dist = math.dist(pt1[idx], pt2[idx])\n",
    "        distance.apend(dist)\n",
    "        \n",
    "    distance = np.array(distance)\n",
    "    mean, stdev = np.mean(distance, axis=0), np.std(distance, axis=0)\n",
    "    \n",
    "    inliers = np.zeros(len(pt1))\n",
    "    score = 0\n",
    "    for idx in range(pointRange):\n",
    "        if np.abs(distance[idx] - mean) < stdev:\n",
    "            inliers[idx] = 1\n",
    "            score += 1\n",
    "\n",
    "\n",
    "\n",
    "    return score, inliers\n",
    "\n",
    "\n",
    "def auto_homography(Ia,Ib, homography_func=None,normalization_func=None):\n",
    "    '''\n",
    "    Computes a homography that maps points from Ia to Ib\n",
    "\n",
    "    Input: Ia and Ib are images\n",
    "    Output: H is the homography\n",
    "\n",
    "    '''\n",
    "    if Ia.dtype == 'float32' and Ib.dtype == 'float32':\n",
    "\n",
    "        Ia = (Ia*255).astype(np.uint8)\n",
    "        Ib = (Ib*255).astype(np.uint8)\n",
    "\n",
    "    Ia_gray = cv2.cvtColor(Ia,cv2.COLOR_BGR2GRAY)\n",
    "    Ib_gray = cv2.cvtColor(Ib,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp_a, des_a = sift.detectAndCompute(Ia_gray,None)\n",
    "    kp_b, des_b = sift.detectAndCompute(Ib_gray,None)    \n",
    "\n",
    "    # BFMatcher with default params\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des_a,des_b, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append(m)\n",
    "\n",
    "    numMatches = int(len(good))\n",
    "\n",
    "    matches = good\n",
    "\n",
    "    # Xa and Xb are 3xN matrices that contain homogeneous coordinates for the N\n",
    "    # matching points for each image\n",
    "    Xa = np.ones((3,numMatches))\n",
    "    Xb = np.ones((3,numMatches))\n",
    "\n",
    "    for idx, match_i in enumerate(matches):\n",
    "        Xa[:,idx][0:2] = kp_a[match_i.queryIdx].pt\n",
    "        Xb[:,idx][0:2] = kp_b[match_i.trainIdx].pt\n",
    "\n",
    "    ## RANSAC\n",
    "    niter = 1000\n",
    "    best_score = 0\n",
    "    n_to_sample = ???? # Put the correct number of points here\n",
    "\n",
    "    for t in range(niter):\n",
    "        # estimate homography\n",
    "        subset = np.random.choice(numMatches, n_to_sample, replace=False)\n",
    "        pts1 = Xa[:,subset]\n",
    "        pts2 = Xb[:,subset]\n",
    "\n",
    "        H_t = homography_func(pts1, pts2, normalization_func) # edit helper code below (computeHomography)\n",
    "\n",
    "\n",
    "        # score homography\n",
    "        Xb_ = np.dot(H_t, Xa) # project points from first image to second using H\n",
    "\n",
    "        score_t, inliers_t = score_projection(Xb[:2,:]/Xb[2,:], Xb_[:2,:]/Xb_[2,:])\n",
    "\n",
    "        if score_t > best_score:\n",
    "            best_score = score_t\n",
    "            H = H_t\n",
    "            in_idx = inliers_t\n",
    "\n",
    "    print('best score: {:02f}'.format(best_score))\n",
    "\n",
    "    # Optionally, you may want to re-estimate H based on inliers\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hgPCp98fQJvh"
   },
   "outputs": [],
   "source": [
    "def computeHomography(pts1, pts2,normalization_func=None):\n",
    "    '''\n",
    "    Compute homography that maps from pts1 to pts2 using SVD. Normalization is optional.\n",
    "     \n",
    "    Input: pts1 and pts2 are 3xN matrices for N points in homogeneous\n",
    "    coordinates. \n",
    "    \n",
    "    Output: H is a 3x3 matrix, such that pts2~=H*pts1\n",
    "    '''\n",
    "    # TO DO\n",
    "    H, status = cv2.findHomography(pts1, pts2)\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fkiAbFqvQJvo"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13344/4211926239.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Load an color image in grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mim1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mim2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# images location\n",
    "im1 = './images/input/frames/f0270.jpg'\n",
    "im2 = './images/input/frames/f0450.jpg'\n",
    "\n",
    "# Load an color image in grayscale\n",
    "im1 = cv2.imread(im1)\n",
    "im2 = cv2.imread(im2)\n",
    "\n",
    "H = auto_homography(im1,im2, computeHomography)\n",
    "print(H/H.max()) \n",
    "\n",
    "# plot the frames here\n",
    "box_pts = np.array([[300, 400, 400, 300, 300], [100, 100, 200, 200, 100], [1, 1, 1, 1, 1]])\n",
    "plt.figure()\n",
    "plt.imshow(im1[:,:,[2,1,0]])\n",
    "plt.plot(box_pts[0,:], box_pts[1, :], 'r-')\n",
    "\n",
    "# TO DO: project points into im2 and display the projected lines on im2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mDd6PwrGQJvw"
   },
   "outputs": [],
   "source": [
    "projectedWidth = 1600\n",
    "projectedHeight = 500\n",
    "Tr = np.array([[1, 0, 660], [0, 1, 120], [0, 0, 1]])\n",
    "\n",
    "# TO DO: warp and blend the two images\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v1PigMkPQJv4"
   },
   "source": [
    "### Part II: Panorama using five key frames\n",
    "\n",
    "Produce a panorama by mapping five key frames [90, 270, 450, 630, 810] onto the same reference frame 450.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2SgCFur1QJwC"
   },
   "outputs": [],
   "source": [
    "key_frames_idx = np.array([90, 270, 450, 630, 810])-1\n",
    "\n",
    "frames = np.zeros((len(key_frames_idx), im1.shape[0], im1.shape[1], im1.shape[2]),dtype='uint8')\n",
    "for n in range(len(key_frames)):\n",
    "  frames[n] = cv2.imread(\"./images/input/frames/f0{num}.jpg\".format(num=str(key_frames_idx[n]+1).zfill(3)))\n",
    "\n",
    "# TO DO solution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "APdyMw_NQJwK"
   },
   "source": [
    "### Part 3: Map the video to the reference plane\n",
    "\n",
    "Project each frame onto the reference frame (using same size panorama) to create a video that shows the portion of the panorama revealed by each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAXyIkYyQJwT"
   },
   "outputs": [],
   "source": [
    "# read all the images\n",
    "import os \n",
    "dir_frames = 'images/input/frames'\n",
    "filenames = []\n",
    "filesinfo = os.scandir(dir_frames)\n",
    "\n",
    "filenames = [f.path for f in filesinfo if f.name.endswith(\".jpg\")]\n",
    "filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "\n",
    "frameCount = len(filenames)\n",
    "frameHeight, frameWidth, frameChannels = cv2.imread(filenames[0]).shape\n",
    "frames = np.zeros((frameCount, frameHeight, frameWidth, frameChannels),dtype='uint8')\n",
    "\n",
    "for idx, file_i in enumerate(filenames):\n",
    "  frames[idx] = cv2.imread(file_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0b8N2rP9PDVL"
   },
   "outputs": [],
   "source": [
    "# TO DO part 3 solution\n",
    "\n",
    "# create your video (see tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dg2O-zH_QJw0"
   },
   "source": [
    "### Part 4: Create background panorama\n",
    "\n",
    "Create a background panorama based on the result from Part 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ammv-rsQJw1"
   },
   "outputs": [],
   "source": [
    "# TO DO part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_IqzWZwrQJw4"
   },
   "source": [
    "### Part 5: Create background movie\n",
    "\n",
    "Generate a movie that looks like the input movie but shows only background pixels. For each frame of the movie, you need to estimate a projection from the panorama to that frame. Your solution can use the background image you created in Part 4 and the per-frame homographies you created in Part 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dzy12p1bQJw4"
   },
   "outputs": [],
   "source": [
    "# TO DO part 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p0y7i7hBQJw7"
   },
   "source": [
    "### Part 6: Create foreground movie\n",
    "\n",
    "In the background video, moving objects are removed. In each frame, those pixels that are different enough than the background color are considered foreground. For each frame determine foreground pixels and generate a movie that emphasizes or includes only foreground pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mcg6jC_9QJw8"
   },
   "outputs": [],
   "source": [
    "# TO DO part 6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G8N-OaHeQJxA"
   },
   "source": [
    "## Bells and whistles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMeDlAhFQJxB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_5_starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
